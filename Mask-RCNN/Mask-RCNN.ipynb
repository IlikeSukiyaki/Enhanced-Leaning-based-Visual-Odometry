{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/972 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 972/972 [00:12<00:00, 77.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# specify image dir and mask save directory\n",
    "save_dir = '/home/logan/Desktop/Multys_something/dataset/sequences/00/mask_3'\n",
    "img_dir = '/home/logan/Desktop/Multys_something/dataset/sequences/00/image_3'\n",
    "\n",
    "# create model and predict \n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "kernel = np.ones((7, 7), np.uint8) # dialation kernel\n",
    "\n",
    "# get all images\n",
    "image_list = glob(os.path.join(img_dir, '*'))\n",
    "image_list.sort()\n",
    "\n",
    "for img_file in tqdm(image_list):\n",
    "    # show images\n",
    "    img = cv2.imread(img_file)\n",
    "    img_name = os.path.basename(img_file)\n",
    "    # print(img_name)\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(rgb_img)\n",
    "    # print(img.shape)\n",
    "\n",
    "    # detect segment\n",
    "    # results = model.predict(source=img.copy(), save=True, save_txt=False, stream=True, verbose=False)\n",
    "    results = model.predict(source=img.copy(), verbose=False)\n",
    "\n",
    "    # create binary mask and save it \n",
    "    for result in results:\n",
    "        if result.masks is None:\n",
    "            object_mask = np.zeros_like(img)\n",
    "            cv2.imwrite(os.path.join(save_dir, img_name), object_mask)\n",
    "            continue\n",
    "        # get array results\n",
    "        masks = result.masks.data\n",
    "        boxes = result.boxes.data\n",
    "        # extract classes\n",
    "        clss = boxes[:, 5]\n",
    "        # print(clss)\n",
    "        # get indices of results where class is 0 (people in COCO)\n",
    "        # people_indices = torch.where(clss in [0,1,2,3,4,5,6,7,8])\n",
    "        indixes = torch.where(clss == 0)[0]\n",
    "        for idx in [1,2,3,4,5,6,7,8]:\n",
    "            car_indices = torch.where(clss == idx)\n",
    "            indixes = torch.cat((indixes, car_indices[0]))\n",
    "        # people_indices = torch.where(clss == 0)\n",
    "        # car_indices = torch.where(clss == 2)\n",
    "        # indixes = torch.cat((people_indices[0], car_indices[0]))\n",
    "        # use these indices to extract the relevant masks\n",
    "        object_masks = masks[indixes]\n",
    "        # scale for visualizing results\n",
    "        object_mask = torch.any(object_masks, dim=0).int()\n",
    "\n",
    "        ## dilation\n",
    "        # object_mask = object_mask.cpu().numpy().astype('uint8') * 255\n",
    "        object_mask = object_mask.cpu().numpy().astype('uint8')\n",
    "        object_mask = cv2.dilate(object_mask, kernel)  * 255\n",
    "        \n",
    "        # resize mask to the same as the input image\n",
    "        object_mask = cv2.resize(object_mask, (img.shape[1], img.shape[0]))\n",
    "        # save to file\n",
    "        cv2.imwrite(os.path.join(save_dir, img_name), object_mask)\n",
    "        # print(object_mask.shape)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(object_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: iopaint: command not found\n"
     ]
    }
   ],
   "source": [
    "# use IOPaint\n",
    "\n",
    "! iopaint run --model=lama --device=cuda --image=/home/logan/Desktop/Multys_something/dataset/image --mask=/home/logan/Desktop/Multys_something/dataset/mask --output=/home/logan/Desktop/Multys_something/dataset/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
